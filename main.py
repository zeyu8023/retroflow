import socket
import struct
import threading
import time
import json
import logging
import os
import sqlite3
from flask import Flask, jsonify, send_file, request
import docker

# --- æ ¸å¿ƒé…ç½®åŒºï¼šåœ¨è¿™é‡Œå®šä¹‰ä½ çš„ NAS æœåŠ¡ ---
# æ ¼å¼ï¼šç«¯å£å·: "æ˜¾ç¤ºåç§°"
# å³ä½¿ Docker API æŒ‚äº†ï¼Œè¿™äº›æœåŠ¡ä¹Ÿä¼šå¼ºåˆ¶æ˜¾ç¤ºåœ¨é¢æ¿ä¸Š
HOST_SERVICES = {
    # åª’ä½“æœåŠ¡
    8096: "Emby",
    8920: "Emby (HTTPS)",
    32400: "Plex",
    8090: "Jellyfin",
    
    # ä¸‹è½½å·¥å…·
    8080: "Qbittorrent",  # å¦‚æœä½ çš„ QB æ˜¯å…¶ä»–ç«¯å£è¯·ä¿®æ”¹
    8999: "Qbittorrent (UI)",
    9091: "Transmission",
    51413: "Transmission (Data)",
    
    # æ ¸å¿ƒæœåŠ¡
    10308: "RetroFlow",
    80: "Nginx (Web)",
    443: "Nginx (SSL)",
    
    # æ–‡ä»¶ä¸ç³»ç»Ÿ
    445: "SMB (æ–‡ä»¶å…±äº«)",
    22: "SSH (ç»ˆç«¯)",
    5000: "ç¾¤æ™– DSM",
    5001: "ç¾¤æ™– DSM (SSL)",
    
    # æ•°æ®åº“
    3306: "MySQL",
    6379: "Redis",
    
    # æ™ºèƒ½å®¶å±…
    8123: "HomeAssistant"
}

# --- å…¨å±€æ•°æ® ---
stats_store = {}
last_saved_stats = {}
lock = threading.Lock()

app = Flask(__name__)
try:
    # å°è¯•è¿æ¥ Dockerï¼Œå¦‚æœå¤±è´¥ä¹Ÿä¸ä¼šå´©æºƒï¼Œä¼šä½¿ç”¨ HOST_SERVICES å…œåº•
    docker_client = docker.from_env()
except Exception as e:
    docker_client = None
    print(f"âš ï¸ Docker API è¿æ¥å¤±è´¥: {e} (å°†ä½¿ç”¨ç«¯å£æ˜ å°„æ¨¡å¼)")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
DB_PATH = 'data/traffic.db'

# --- æ•°æ®åº“ ---
def init_db():
    if not os.path.exists('data'):
        os.makedirs('data')
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS history 
                 (timestamp INTEGER, name TEXT, upload INTEGER, download INTEGER)''')
    c.execute('''CREATE INDEX IF NOT EXISTS idx_time ON history (timestamp)''')
    conn.commit()
    conn.close()

def ensure_stats(name, net_type, init_only=False):
    """ç¡®ä¿æœåŠ¡åœ¨åˆ—è¡¨ä¸­"""
    if name not in stats_store:
        stats_store[name] = {
            "name": name, 
            "type": net_type, 
            "upload": 0, 
            "download": 0,
            "speed_up": 0,
            "speed_down": 0
        }

# --- åˆå§‹åŒ–é€»è¾‘ (å…³é”®ä¿®æ”¹) ---
def init_services():
    """å¯åŠ¨æ—¶æŠŠé…ç½®å¥½çš„æœåŠ¡å…¨éƒ¨åŠ è½½è¿›å»ï¼Œé˜²æ­¢åˆ—è¡¨ä¸ºç©º"""
    with lock:
        # 1. å…ˆåŠ è½½æ‰‹åŠ¨é…ç½®çš„æœåŠ¡ (Hostæ¨¡å¼)
        for port, name in HOST_SERVICES.items():
            ensure_stats(name, "host")
            
        # 2. å†å°è¯•åŠ è½½ Docker å®¹å™¨ (Bridgeæ¨¡å¼)
        if docker_client:
            try:
                containers = docker_client.containers.list()
                for c in containers:
                    # å¦‚æœå®¹å™¨åå·²ç»åœ¨æ‰‹åŠ¨é…ç½®é‡Œäº†ï¼Œå°±è·³è¿‡ï¼Œé¿å…é‡å¤
                    # è¿™é‡Œä¸»è¦ä¸ºäº†æ•è·é‚£äº›ä¸åœ¨ HOST_SERVICES é‡Œçš„ Bridge å®¹å™¨
                    if c.attrs['HostConfig']['NetworkMode'] != 'host':
                        ensure_stats(c.name, "bridge")
                logging.info(f"âœ… Docker API å·²è¿æ¥ï¼Œæ‰«æåˆ° {len(containers)} ä¸ªå®¹å™¨")
            except Exception as e:
                logging.error(f"âŒ Docker æ‰«æå¤±è´¥: {e}")
        else:
            logging.warning("âš ï¸ æœªæ£€æµ‹åˆ° Docker APIï¼Œä»…æ˜¾ç¤º HOST_SERVICES é…ç½®çš„æœåŠ¡")

# --- æŠ“åŒ…æ¨¡å— ---
def start_sniffer(interface="eth0"):
    logging.info(f"ğŸ•¸ï¸ [Sniffer] å¼€å§‹ç›‘å¬ {interface}...")
    try:
        sock = socket.socket(socket.AF_PACKET, socket.SOCK_RAW, socket.ntohs(0x0003))
        sock.bind((interface, 0))
    except Exception as e:
        logging.error(f"âŒ æŠ“åŒ…å¤±è´¥ (è¯·ç¡®ä¿ --privileged): {e}")
        return

    while True:
        try:
            raw_data, _ = sock.recvfrom(65535)
            packet_len = len(raw_data)
            
            # å¿«é€Ÿè§£æ IP å¤´
            # åç§»14å­—èŠ‚(Ethernet header)
            if raw_data[12:14] != b'\x08\x00': continue # é IPv4

            ip_header = raw_data[14:34]
            # å–å‡º IP åè®®å· (ç¬¬10ä¸ªå­—èŠ‚, index 9)
            protocol = ip_header[9] 
            if protocol != 6 and protocol != 17: continue # é TCP/UDP

            # å–å‡º IP å¤´é•¿åº¦ (å‰4ä½)
            ihl = (ip_header[0] & 0xF) * 4
            
            # è§£æç«¯å£ (TCP/UDP å¤´çš„å‰4å­—èŠ‚æ˜¯ src_port, dst_port)
            transport_offset = 14 + ihl
            # struct unpack '!HH' è¯»å–ä¸¤ä¸ª unsigned short (2å­—èŠ‚)
            src_port, dst_port = struct.unpack('!HH', raw_data[transport_offset:transport_offset+4])

            with lock:
                # æ ¸å¿ƒåŒ¹é…é€»è¾‘ï¼šåªåŒ¹é… HOST_SERVICES å®šä¹‰çš„ç«¯å£
                # ä¸‹è½½ (åˆ«äºº -> NASç«¯å£)
                if dst_port in HOST_SERVICES:
                    name = HOST_SERVICES[dst_port]
                    ensure_stats(name, "host")
                    stats_store[name]["download"] += packet_len
                
                # ä¸Šä¼  (NASç«¯å£ -> åˆ«äºº)
                if src_port in HOST_SERVICES:
                    name = HOST_SERVICES[src_port]
                    ensure_stats(name, "host")
                    stats_store[name]["upload"] += packet_len

        except Exception:
            continue

# --- Docker ç›‘æ§ (Bridge) ---
def start_docker_monitor():
    while True:
        if not docker_client:
            time.sleep(10)
            continue
        try:
            # åªæ˜¯ä¸ºäº†å‘ç°æ–°å¯åŠ¨çš„ bridge å®¹å™¨
            containers = docker_client.containers.list()
            for c in containers:
                if c.attrs['HostConfig']['NetworkMode'] != 'host':
                    with lock:
                        ensure_stats(c.name, "bridge")
        except:
            pass
        time.sleep(5)

# --- å†å²è®°å½• ---
def save_history_task():
    while True:
        time.sleep(60)
        timestamp = int(time.time())
        with lock:
            conn = sqlite3.connect(DB_PATH)
            c = conn.cursor()
            for name, data in stats_store.items():
                current_up = data['upload']
                current_down = data['download']
                last = last_saved_stats.get(name, {'upload': 0, 'download': 0})
                
                delta_up = current_up - last['upload']
                delta_down = current_down - last['download']
                
                if delta_up > 0 or delta_down > 0:
                    c.execute("INSERT INTO history VALUES (?, ?, ?, ?)", 
                              (timestamp, name, delta_up, delta_down))
                
                last_saved_stats[name] = {'upload': current_up, 'download': current_down}
            conn.commit()
            conn.close()

# --- è·¯ç”± ---
@app.route('/')
def index():
    return send_file('index.html')

@app.route('/api/realtime')
def get_realtime():
    with lock:
        # ç®€å•æŒ‰ä¸‹è½½é‡æ’åºï¼Œæ´»è·ƒçš„åœ¨å‰
        data = list(stats_store.values())
        return jsonify(data)

@app.route('/api/history')
def get_history():
    time_range = request.args.get('range', 'day')
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    now = int(time.time())
    
    if time_range == 'day':
        start_time = now - 24 * 3600
        fmt = '%H:00'
    elif time_range == 'month':
        start_time = now - 30 * 24 * 3600
        fmt = '%m-%d'
    else:
        start_time = now - 365 * 24 * 3600
        fmt = '%Y-%m'

    sql = f"""
        SELECT strftime('{fmt}', datetime(timestamp, 'unixepoch', 'localtime')) as time_label,
               name, sum(upload), sum(download)
        FROM history WHERE timestamp > ?
        GROUP BY time_label, name
        ORDER BY timestamp
    """
    c.execute(sql, (start_time,))
    rows = c.fetchall()
    conn.close()
    
    result = {}
    for row in rows:
        label, name, up, down = row
        if label not in result: result[label] = {}
        if name not in result[label]: result[label][name] = {'up': 0, 'down': 0}
        result[label][name]['up'] += up
        result[label][name]['down'] += down
    return jsonify(result)

if __name__ == '__main__':
    init_db()
    # å…³é”®ï¼šå¯åŠ¨æ—¶å°±åŠ è½½æ‰€æœ‰é…ç½®çš„æœåŠ¡
    init_services()
    
    t1 = threading.Thread(target=start_sniffer, args=("eth0",), daemon=True)
    t1.start()
    t2 = threading.Thread(target=start_docker_monitor, daemon=True)
    t2.start()
    t3 = threading.Thread(target=save_history_task, daemon=True)
    t3.start()

    logging.info("ğŸš€ RetroFlow Ready :10308")
    app.run(host='0.0.0.0', port=10308)