import socket
import struct
import threading
import time
import json
import logging
import os
import sqlite3
import psutil
from flask import Flask, jsonify, send_file, request
import docker

# --- ç«¯å£æ˜ å°„ (ä»…ç”¨äº Host æ¨¡å¼å®¹å™¨çš„è¯†åˆ«) ---
PORT_MAP = {
    8096: "Emby (åª’ä½“)", 8920: "Emby (SSL)",
    32400: "Plex", 8090: "Jellyfin",
    8080: "Qbittorrent", 8999: "QBç®¡ç†å£",
    9091: "Transmission", 51413: "Transmissionæ•°æ®",
    10308: "RetroFlow",
    80: "Web (HTTP)", 443: "Web (SSL)",
    445: "SMBå…±äº«", 22: "SSH",
    3306: "MySQL", 6379: "Redis",
    8123: "HomeAssistant", 5000: "DSM", 5001: "DSM (SSL)"
}

stats_store = {}
last_saved_stats = {}
system_status = {}
# ç”¨äºå­˜å‚¨ Docker API ä¸Šä¸€æ¬¡çš„è¯»æ•°ï¼Œç”¨æ¥è®¡ç®—å¢é‡
docker_last_read = {} 

lock = threading.Lock()

app = Flask(__name__)
try:
    docker_client = docker.from_env()
except:
    docker_client = None

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')
DB_PATH = 'data/traffic.db'

def init_db():
    if not os.path.exists('data'): os.makedirs('data')
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS history 
                 (timestamp INTEGER, name TEXT, upload INTEGER, download INTEGER)''')
    c.execute('''CREATE INDEX IF NOT EXISTS idx_time ON history (timestamp)''')
    conn.commit()
    conn.close()

def ensure_stats(name, net_type):
    if name not in stats_store:
        stats_store[name] = {"name": name, "type": net_type, "upload": 0, "download": 0}

# --- å¼•æ“ A: Docker API ç›´è¯» (é’ˆå¯¹ Bridge æ¨¡å¼) ---
def start_docker_monitor():
    """ç›´æ¥è¯»å–å®¹å™¨è™šæ‹Ÿç½‘å¡çš„è®¡æ•°å™¨ï¼Œ100% ç²¾å‡†"""
    logging.info("ğŸš€ [å¼•æ“A] Docker API ç›‘æ§å·²å¯åŠ¨ (Bridgeç²¾å‡†æ¨¡å¼)")
    while True:
        if not docker_client:
            time.sleep(5)
            continue
            
        try:
            containers = docker_client.containers.list()
            
            for c in containers:
                name = c.name
                net_mode = c.attrs['HostConfig']['NetworkMode']
                
                # åªå¤„ç†é Host æ¨¡å¼ (Bridge, Macvlan ç­‰)
                if net_mode != 'host':
                    with lock:
                        ensure_stats(name, "bridge")
                    
                    try:
                        # è·å–å®æ—¶ç»Ÿè®¡ (ä¸æµå¼ï¼Œåªå–ä¸€æ¬¡å¿«ç…§)
                        stats = c.stats(stream=False)
                        
                        # è®¡ç®—æµé‡æ€»å’Œ (å¯èƒ½æœ‰å¤šä¸ªç½‘å¡)
                        rx_total = 0 # ä¸‹è½½
                        tx_total = 0 # ä¸Šä¼ 
                        networks = stats.get('networks', {})
                        
                        if networks:
                            for iface, data in networks.items():
                                rx_total += data['rx_bytes']
                                tx_total += data['tx_bytes']
                        
                        # --- å·®å€¼è®¡ç®—é€»è¾‘ ---
                        # Docker API è¿”å›çš„æ˜¯å®¹å™¨å¯åŠ¨åçš„ç´¯è®¡æ€»é‡
                        # æˆ‘ä»¬éœ€è¦è®¡ç®— "è‡ªä¸Šæ¬¡è¯»å–ä»¥æ¥å¢åŠ äº†å¤šå°‘"
                        if name in docker_last_read:
                            last_rx = docker_last_read[name]['rx']
                            last_tx = docker_last_read[name]['tx']
                            
                            # è®¡ç®—å¢é‡ (å¦‚æœé‡å¯äº†å®¹å™¨ï¼Œæ•°å€¼å˜å°ï¼Œåˆ™å¿½ç•¥æœ¬æ¬¡)
                            delta_rx = rx_total - last_rx
                            delta_tx = tx_total - last_tx
                            
                            if delta_rx >= 0 and delta_tx >= 0:
                                with lock:
                                    # ç´¯åŠ åˆ°æˆ‘ä»¬çš„ä¸»å­˜å‚¨é‡Œ
                                    stats_store[name]['download'] += delta_rx
                                    stats_store[name]['upload'] += delta_tx
                        
                        # æ›´æ–°ä¸Šä¸€æ¬¡è¯»æ•°
                        docker_last_read[name] = {'rx': rx_total, 'tx': tx_total}
                        
                    except Exception as e:
                        # å®¹å™¨å¯èƒ½åˆšå¯åŠ¨æˆ–æ­£å¥½åœæ­¢
                        pass

        except Exception as e:
            logging.error(f"Docker API è½®è¯¢é”™è¯¯: {e}")
            
        # 1ç§’åˆ·æ–°ä¸€æ¬¡ï¼Œä¿è¯å®æ—¶æ€§
        time.sleep(1)

# --- å¼•æ“ B: æŠ“åŒ… (é’ˆå¯¹ Host æ¨¡å¼) ---
def start_sniffer(interface="eth0"):
    """é’ˆå¯¹ Host æ¨¡å¼å®¹å™¨çš„ç«¯å£æµé‡åˆ†æ"""
    logging.info(f"ğŸ•¸ï¸ [å¼•æ“B] æŠ“åŒ…ç›‘æ§å·²å¯åŠ¨ (Hostå…¼å®¹æ¨¡å¼) - {interface}")
    try:
        sock = socket.socket(socket.AF_PACKET, socket.SOCK_RAW, socket.ntohs(0x0003))
        sock.bind((interface, 0))
    except Exception as e:
        logging.error(f"âŒ æŠ“åŒ…å¤±è´¥: {e}")
        return

    while True:
        try:
            raw_data, _ = sock.recvfrom(65535)
            packet_len = len(raw_data)
            
            if raw_data[12:14] != b'\x08\x00': continue # IPv4
            ip_h = raw_data[14:34]
            if ip_h[9] != 6 and ip_h[9] != 17: continue # TCP/UDP
            
            ihl = (ip_h[0] & 0xF) * 4
            src_port, dst_port = struct.unpack('!HH', raw_data[14+ihl:14+ihl+4])

            with lock:
                # ä»…åŒ¹é… Host æ¨¡å¼çš„å·²çŸ¥ç«¯å£
                # Bridge æ¨¡å¼çš„æµé‡ç”±å¼•æ“ A æ¥ç®¡ï¼Œè¿™é‡Œä¸å†å¤„ç†ï¼Œé¿å…é‡å¤æˆ–è¯¯åˆ¤
                
                # ä¸‹è½½
                if dst_port in PORT_MAP:
                    name = PORT_MAP[dst_port]
                    # åªæœ‰å½“è¯¥æœåŠ¡è¢«æ ‡è®°ä¸º host æ—¶æ‰ç”±æŠ“åŒ…ç»Ÿè®¡
                    # (æˆ–è€…å°šæœªè¢«è¯†åˆ«ç±»å‹çš„æœåŠ¡)
                    if name not in stats_store or stats_store[name]['type'] == 'host':
                        ensure_stats(name, "host")
                        stats_store[name]["download"] += packet_len
                
                # ä¸Šä¼ 
                if src_port in PORT_MAP:
                    name = PORT_MAP[src_port]
                    if name not in stats_store or stats_store[name]['type'] == 'host':
                        ensure_stats(name, "host")
                        stats_store[name]["upload"] += packet_len
        except:
            continue

# --- ç³»ç»Ÿç›‘æ§ ---
def monitor_system_task():
    while True:
        try:
            with lock:
                system_status['cpu'] = psutil.cpu_percent(interval=None)
                mem = psutil.virtual_memory()
                system_status['mem_percent'] = mem.percent
                system_status['boot_time'] = psutil.boot_time()
        except: pass
        time.sleep(2)

# --- å†å²è®°å½• ---
def save_history_task():
    while True:
        time.sleep(60)
        timestamp = int(time.time())
        with lock:
            conn = sqlite3.connect(DB_PATH)
            c = conn.cursor()
            for name, data in stats_store.items():
                curr_up, curr_down = data['upload'], data['download']
                last = last_saved_stats.get(name, {'u':0, 'd':0})
                du, dd = curr_up - last['u'], curr_down - last['d']
                if du > 0 or dd > 0:
                    c.execute("INSERT INTO history VALUES (?,?,?,?)", (timestamp, name, du, dd))
                last_saved_stats[name] = {'u': curr_up, 'd': curr_down}
            conn.commit()
            conn.close()

# --- è·¯ç”± ---
@app.route('/')
def index(): return send_file('index.html')

@app.route('/api/status')
def get_status():
    with lock:
        return jsonify({"containers": list(stats_store.values()), "system": system_status})

@app.route('/api/history')
def get_history():
    range_arg = request.args.get('range', 'day')
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    now = int(time.time())
    if range_arg == 'day': start, fmt = now-86400, '%H:00'
    elif range_arg == 'month': start, fmt = now-2592000, '%m-%d'
    else: start, fmt = now-31536000, '%Y-%m'
    
    c.execute(f"SELECT strftime('{fmt}', datetime(timestamp, 'unixepoch', 'localtime')) as t, name, sum(upload), sum(download) FROM history WHERE timestamp > ? GROUP BY t, name ORDER BY timestamp", (start,))
    rows = c.fetchall()
    conn.close()
    
    res = {}
    for t, n, u, d in rows:
        if t not in res: res[t] = {}
        if n not in res[t]: res[t][n] = {'up':0, 'down':0}
        res[t][n]['up']+=u; res[t][n]['down']+=d
    return jsonify(res)

if __name__ == '__main__':
    init_db()
    # å¯åŠ¨åŒå¼•æ“
    threading.Thread(target=start_sniffer, args=("eth0",), daemon=True).start()
    threading.Thread(target=start_docker_monitor, daemon=True).start()
    threading.Thread(target=save_history_task, daemon=True).start()
    threading.Thread(target=monitor_system_task, daemon=True).start()
    
    logging.info("ğŸš€ RetroFlow Dual-Engine Ready :10308")
    app.run(host='0.0.0.0', port=10308)